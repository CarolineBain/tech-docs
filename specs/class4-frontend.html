<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Class 4 dynamic web interface</title>
    <link rel="stylesheet" href="reset.css" media="all">
    <script src="script.js" charset="utf-8"></script>
</head>
<body>
    <h1>Class 4 front-end technical specification</h1>
    <div id="toc"></div>
    <h2>Introduction</h2>
    <p>The existing front-end for Class 4 statistics is not scalable. As
    additional menu options are added the time required to generate the
    extra plots grows super-linearly. This scaling is a direct result
    of the system's architecture. The decision was taken early on to serve
    pre-computed static images. Initially, this seemed like a good idea
    since it was simple to implement and could quickly visualise results. But
    over time the limitations of this approach have been exposed. A more
    scalable solution, although not a panacea, would be to allow a user
    to dynamically generate images.</p>
    <p>The new approach aims to leverage web standards and
    JavaScript visualisation libraries such as d3.js to create a
    dynamic and interactive user experience. Unique technical challenges
    exist with this approach, such as converting SVG to PNG, but overall
    the benefits of dynamically generated content outweigh the drawbacks
    of exhaustively generating static images.</p>
    <h2>Overview</h2>
    <p>Exploring ocean verification results at present requires the user to
    repeatedly generate static images from NetCDF files using a relatively
    complicated command line tool called c4plot.
    To isolate a particular issue, the user must iteratively re-run c4plot
    using more and more precise arguments to bisect the affected
    dates.</p>
    <p>A more desirable solution would be for the user to click/zoom to the
    affected portion of the time series without having to re-generate images. Indeed,
    the user should not even need access to the underlying files to be able to
    explore the data. The front-end should re-render the desired portion of
    the data dynamically.</p>
    <p>The present system serves two uses. It is both a monitoring tool and a tool to track
    our performance relative to other forecasting centers. However, since it
    can only generate static images it cannot simultaneously display both
    a high-level and low-level view of the data. The proposed solution aims to
    unify these use cases by providing the user with an interface adapted for
    both diagnosis and long term summarisation.</p>

    <h2>Current system</h2>
    <img src="images/current-flow.gif" alt="" />
    <p>The workflow under the current system involves a user (with access
    to statistics files) either plotting a vast number of images when
    trying to anticipate all users needs or iteratively re-plotting individual
    images from the command line when diagnosing a particular issue. Either
    scenario is time consuming and a waste of resources, both human and computational.
    The web site, in it's current format, is solely a menu system for navigating
    to images. It has no ability to generate images if an image is not available
    nor does it have the ability to rescale axes of a particular image. This
    design gives rise to the following issues.</p>

    <h3>Labour intensive data exploration</h3>
    <p>Data exploration with c4plot is time consuming. Under the current
    system to find a date related to a spike, a user must regenerate
    plots with shorter and shorter time intervals until the x-axis
    labels resolve the date. A JavaScript approach would simply show
    a tooltip on hover with the date information. The c4plot system
    also requires the user to restore the original image after the
    data exploration has completed, if the website is viewable by other
    users.</p>

    <h3>Spike obfuscation</h3>
    <p>Since the images are generated once and can not easily be re-generated
    it is often the case that a missing data value, erroneously treated as a
    valid data point, can obfuscate the information in an entire image. In
    some cases this may render the utility of an entire website valueless as
    users are mainly interested in that one image.
    The proposed dynamic rendering solution should have a feature to
    eliminate the obscuring effects of spikes, by either allowing the user
    to adjust the y-limits or to filter bad data points.</p>

    <h3>Combinatorial explosion of plots</h3>
    <p>While having one or two metrics displayed for a handful of regions is
    light-weight and lightning fast. Turning on all bells and whistles
    can quickly result in the generation of several million plots. Of which,
    inevitably the plot needed to diagnose a problem will not be present.
    Migrating to an on demand system of plotting will drastically reduce
    the need to populate the entire plotting-space ahead of time.</p>

    <h3>Cluttered images</h3>
    <p>In some cases there are dozens of models being compared. In these
    scenarios all available lines are displayed simultaneously which results
    in cluttered and hard to read plots. Instead of re-plotting subsets of
    the models, a dynamic solution would provide the user with checkboxes
    to add/remove individual models as desired.</p>

    <h3>User driven plotting</h3>
    <p>More and more, users of the data are requesting that plots be generated
    in a bespoke manner. Individually, these requests seem sensible. But
    aggregated over half a dozen users it becomes difficult to service their
    requests. A tool is needed to generate bespoke plots on a per-user basis
    without a need for manual intervention from the site-owner.</p>

    <h3>Rigid labelling</h3>
    <p>Opening up the legend, x and y axis labels and title to user customisation
    would allow users to sculpt bespoke plots by themselves without having to
    email data-owners to re-plot single images. The benefits of this feature
    is a human-resource scaling not a computational scaling.</p>

    <h3>Rigid line styling</h3>
    <p>In the same vein as labelling allowing the user to customise individual colors,
    markers and linestyles will remove the burden currently on the data-owner
    to produce better looking plots.</p>

    <h2>Proposed system</h2>
    <img src="images/future-flow.gif" alt="" />
    <p>By eliminating interaction with the command line, the replacement tool should
    make it easier to diagnose issues affecting one or more ocean models. Instead
    of running a command line tool and refreshing their browser, a user can
    simply click on a checkbox and display particular trends of interest.
    </p>
        <h3>Features</h3>
        As well as reproducing all options from the current menu system
        the new page will also provide the following features
        <ul>
            <li>Add/remove individual lines</li>
            <li>Pan/zoom to data of interest</li>
            <li>Tooltips to reveal the values of particular data points</li>
            <li>Custom colors and line styles for individual trends</li>
            <li>Custom labelling, e.g. legend, x-axis, y-axis and title labels</li>
            <li>Save SVG elements to PNG</li>
            <li>Reproduce plot state from URL hash</li>
            <li>Signal processing of raw trends using JavaScript</li>
        </ul>
        <p>The intention of the above features is to enable the user to explore
        the data and to customise their plot(s) to their own tastes. This should
        take the burden of generating plots away from the data owner altogether.
        The data owner is simply responsible for computing the raw statistics, the
        user is then free to process the data using the above features.</p>
        <h3>Libraries</h3>
        <ul>
            <li><a href="https://d3js.org/">D3.js - Data Driven Documents</a></li>
        </ul>
        <p>The only anticipated dependency of this new tool is a library
        called d3.js, which will be used to do the heavy lifting of 
        rendering the SVG elements.</p>
        <h3>Server-side SVG to PNG</h3>
        <p>The above proposal has been technically feasible for many years
        but was never entertained as a viable solution since there
        was a requirement to produce publication quality PNG images.
        Python's matplotlib readily produced high-quality images with little
        effort so the alternative JavaScript approaches were never pursued.
        The technical challenge that needs to be overcome is to find a way
        to convert SVG to PNG from the browser.</p>
        <p>Given that a dedicated verification server is not a possibility,
        some thought must be given to find a solution. The most common general
        purpose server available to all staff is an Apache server with
        very few modules loaded. All that is required is access via PHP to
        an image conversion tool such as convert or ImageMagick.</p>
    <h2>Road map</h2>
    <p>The above features will not be available at the first release, version 0.1.0. The
    intention is to produce a minimal viable product (MVP) during the first
    sprint and add layers of features at each subsequent iteration. Although not
    the actual release schedule, the following list gives some idea to the rate of
    progress expected. And also an idea of the capabilities of the finished product.</p>
    <ul>
        <li>0.1.0 - Display time series images equivalent of c4plot</li>
        <li>0.2.0 - Extend menu to replicate c4plot front-end options, regions, metrics etc.</li>
        <li>0.3.0 - Customise colors, y-limits and add/remove lines</li>
        <li>0.4.0 - Support tool tips, custom labels and legends</li>
        <li>0.5.0 - Add signal processing, annual/monthly means, rolling means etc.</li>
        <li>0.6.0 - Add lead time diagrams with customisable forecast modes/lead times</li>
        <li>0.7.0 - Add profile diagrams with zoomable depths</li>
        <li>0.8.0 - Add pan/zoom feature to ease navigation</li>
        <li>0.9.0 - Add SVG to PNG support (if viable)</li>
        <li>0.10.0 - Add support for relative statistics, user selected reference trend</li>
        <li>0.11.0 - Add spike filtering, a potentially easier to use y-limit selector</li>
        <li>0.12.0 - Add cross-browser compatibility, IE, firefox, Chrome etc.</li>
        <li>...</li>
        <li>1.0.0 - First stable release</li>
    </ul>
    <p>From 1.0.0 onwards the tool will be considered stable. Features
    implemented at that point will be maintained for backwards compatibility
    purposes.</p>
    <h2>Testing strategy, design principles and philosophy</h2>
    <p>The development cycle will place an emphasis on having tests, not
    necessarily test-first development or completely fine grained unit
    tests, but certainly having tests will be key to the success of the
    application. When extending the code, design patterns that encourage
    decoupling will be used where appropriate. Care will be taken
    to only use a design pattern when the benefits of using it are staggering,
    as even a single layer of indirection can add an unacceptable cognitive
    load to future readers of the code.
    MV* patterns are an obvious example of a pattern that pays for itself.
    It is so common place that all front-end developers know at least one
    and it reduces lines of code since it is a natural fit to event-driven applications.</p>
    <p>Where possible the front-end will be written in pure JavaScript to
    be as simple as possible and to prevent frameworks from restricting
    the design too much. As JavaScript is a functional language with first-class
    functions it seems wise to opt for functional programming constructs
    where appropriate. For example, Promises will be favoured over call backs
    and pure functions will be favoured over objects with state.</p>
    <h2>Code quality</h2>
    <p>Adding features without writing tests is a good way to prototype a
    design and to quickly get an application off the ground. But it can quickly
    lead to spaghetti code if care isn't taken to clean the code on a regular
    basis. Having automated tests while they themselves don't guarantee code quality.
    They give developers the confidence to clean up the code
    safe in the knowledge that their changes will not break the software.
    Or if they do break the code, it will give the developer a chance to
    improve the test suite to ensure future breakages do not re-emerge.</p>
    <h2>Old browser support</h2>
    <p>To make the most of the latest language features in ECMAScript 6 (and ES7), this
    application will make no effort to support old browsers. But since it will likely
    be used in pods and conference rooms that only have Internet Explorer some effort
    will be put in to ensuring cross browser compatibility.</p>
    <h2>Summary</h2>
    <p>The existing Class 4 front-end while functional and full-featured is not scalable
    and is highly rigid. The replacement system should solve the scalability and flexibility
    problems by eliminating the need to pre-generate images daily. It will allow users to
    customise individual plots to their chosen aesthetic needs. And hopefully extend
    its functionality beyond the existing system given enough time.</p>
    <p>The features outlined above will be implemented in an organised way with
    release notes accompanying each significant upgrade. The overall workload is not
    expected to be high but the release velocity is expected to decrease as the size of the
    code base grows.</p>
</body>
</html>
